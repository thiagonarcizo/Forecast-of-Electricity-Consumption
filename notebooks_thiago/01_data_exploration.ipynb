{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cf1324",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --quiet matplotlib numpy pandas scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4d81d",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f42fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "782f52c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: /Users/thiagonarcizo/Code/EI-ST4/Forecast-of-Electricity-Consumption\n"
     ]
    }
   ],
   "source": [
    "# Changing the path to the root of the repository\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    current_path = os.getcwd()\n",
    "    root_path = os.path.abspath(os.path.join(current_path, '..'))\n",
    "    os.chdir(root_path)\n",
    "    print(f'Changed working directory to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523237d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "acorn_details = pd.read_csv('data/00_raw/acorn_details.csv', encoding='ISO-8859-1')\n",
    "temperatures = pd.read_csv('data/00_raw/temperatures.csv', sep=';', decimal=',', encoding='utf-8')\n",
    "uk_bank_holidays = pd.read_csv('data/00_raw/uk_bank_holidays.csv')\n",
    "weather_daily = pd.read_csv('data/00_raw/weather_daily_darksky.csv')\n",
    "weather_hourly = pd.read_csv('data/00_raw/weather_hourly_darksky.csv')\n",
    "\n",
    "# Load processed data from parquet\n",
    "group_4_daily_predict = pd.read_parquet('data/02_processed/parquet/group_4_daily_predict.parquet')\n",
    "group_4_half_hourly_predict = pd.read_parquet('data/02_processed/parquet/group_4_half_hourly_predict.parquet')\n",
    "group_4_daily = pd.read_parquet('data/02_processed/parquet/group_4_daily.parquet')\n",
    "group_4_half_hourly = pd.read_parquet('data/02_processed/parquet/group_4_half_hourly.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee4fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Datetime formats\n",
    "temperatures['DateTime'] = pd.to_datetime(temperatures['DateTime'], format='mixed')\n",
    "uk_bank_holidays['Bank holidays'] = pd.to_datetime(uk_bank_holidays['Bank holidays'], format='mixed')\n",
    "\n",
    "# Convert all datetime-like columns in weather_daily to datetime format\n",
    "datetime_columns = ['temperatureMaxTime', 'temperatureMinTime', 'apparentTemperatureMinTime', \n",
    "                   'apparentTemperatureHighTime', 'time', 'sunsetTime', 'sunriseTime', \n",
    "                   'temperatureHighTime', 'uvIndexTime', 'temperatureLowTime', \n",
    "                   'apparentTemperatureMaxTime', 'apparentTemperatureLowTime']\n",
    "\n",
    "for col in datetime_columns:\n",
    "    weather_daily[col] = pd.to_datetime(weather_daily[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5e654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL AND NaN ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "ACORN_DETAILS:\n",
      "  Total nulls: 1\n",
      "  Total NaNs: 1\n",
      "  HAS ISSUES\n",
      "  Columns with nulls: {'REFERENCE': 1}\n",
      "  Columns with NaNs: {'REFERENCE': 1}\n",
      "\n",
      "TEMPERATURES:\n",
      "  Total nulls: 252\n",
      "  Total NaNs: 252\n",
      "  HAS ISSUES\n",
      "  Columns with nulls: {'Temperature': 252}\n",
      "  Columns with NaNs: {'Temperature': 252}\n",
      "\n",
      "UK_BANK_HOLIDAYS:\n",
      "  Total nulls: 0\n",
      "  Total NaNs: 0\n",
      "  OK - No nulls or NaNs\n",
      "\n",
      "WEATHER_DAILY:\n",
      "  Total nulls: 3\n",
      "  Total NaNs: 3\n",
      "  HAS ISSUES\n",
      "  Columns with nulls: {'cloudCover': 1, 'uvIndex': 1, 'uvIndexTime': 1}\n",
      "  Columns with NaNs: {'cloudCover': 1, 'uvIndex': 1, 'uvIndexTime': 1}\n",
      "\n",
      "WEATHER_HOURLY:\n",
      "  Total nulls: 13\n",
      "  Total NaNs: 13\n",
      "  HAS ISSUES\n",
      "  Columns with nulls: {'pressure': 13}\n",
      "  Columns with NaNs: {'pressure': 13}\n",
      "\n",
      "GROUP_4_DAILY_PREDICT:\n",
      "  Total nulls: 96\n",
      "  Total NaNs: 96\n",
      "  HAS ISSUES\n",
      "  Columns with nulls: {'Conso_kWh_predict': 96}\n",
      "  Columns with NaNs: {'Conso_kWh_predict': 96}\n",
      "\n",
      "GROUP_4_HALF_HOURLY_PREDICT:\n",
      "  Total nulls: 288\n",
      "  Total NaNs: 288\n",
      "  HAS ISSUES\n",
      "  Columns with nulls: {'Conso_moy_predict': 288}\n",
      "  Columns with NaNs: {'Conso_moy_predict': 288}\n",
      "\n",
      "GROUP_4_DAILY:\n",
      "  Total nulls: 0\n",
      "  Total NaNs: 0\n",
      "  OK - No nulls or NaNs\n",
      "\n",
      "GROUP_4_HALF_HOURLY:\n",
      "  Total nulls: 0\n",
      "  Total NaNs: 0\n",
      "  OK - No nulls or NaNs\n",
      "\n",
      "==================================================\n",
      "SUMMARY:\n",
      "OK dataframes (3): ['uk_bank_holidays', 'group_4_daily', 'group_4_half_hourly']\n",
      "Problematic dataframes (6): ['acorn_details', 'temperatures', 'weather_daily', 'weather_hourly', 'group_4_daily_predict', 'group_4_half_hourly_predict']\n"
     ]
    }
   ],
   "source": [
    "# Function to check for nulls and NaNs\n",
    "def check_nulls_and_nans(df):\n",
    "    \"\"\"\n",
    "    Check for null values and NaN values in a DataFrame\n",
    "    Returns two Series: one for nulls count and one for NaNs count\n",
    "    \"\"\"\n",
    "    nulls = df.isnull().sum()\n",
    "    nans = df.isna().sum()\n",
    "    return nulls, nans\n",
    "\n",
    "# Checking Null values and NaN in the dataframes\n",
    "# Initialize empty dictionaries to store null/NaN information\n",
    "nulls_nans_info = {}\n",
    "df_names = ['acorn_details', 'temperatures', 'uk_bank_holidays', 'weather_daily', 'weather_hourly',\n",
    "           'group_4_daily_predict', 'group_4_half_hourly_predict', 'group_4_daily', 'group_4_half_hourly']\n",
    "\n",
    "# Check each dataframe and store results\n",
    "for i, df in enumerate(dfs):\n",
    "    nulls, nans = check_nulls_and_nans(df)\n",
    "    nulls_nans_info[df_names[i]] = (nulls, nans)\n",
    "\n",
    "# Display results and identify which dataframes are OK (no nulls/NaNs)\n",
    "print(\"NULL AND NaN ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "ok_dataframes = []\n",
    "problematic_dataframes = []\n",
    "\n",
    "for df_name, (nulls, nans) in nulls_nans_info.items():\n",
    "    total_nulls = nulls.sum()\n",
    "    total_nans = nans.sum()\n",
    "    \n",
    "    print(f\"\\n{df_name.upper()}:\")\n",
    "    print(f\"  Total nulls: {total_nulls}\")\n",
    "    print(f\"  Total NaNs: {total_nans}\")\n",
    "    \n",
    "    if total_nulls > 0 or total_nans > 0:\n",
    "        print(f\"  HAS ISSUES\")\n",
    "        problematic_dataframes.append(df_name)\n",
    "        # Show which columns have issues\n",
    "        if total_nulls > 0:\n",
    "            print(f\"  Columns with nulls: {nulls[nulls > 0].to_dict()}\")\n",
    "        if total_nans > 0:\n",
    "            print(f\"  Columns with NaNs: {nans[nans > 0].to_dict()}\")\n",
    "    else:\n",
    "        print(f\"  OK - No nulls or NaNs\")\n",
    "        ok_dataframes.append(df_name)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SUMMARY:\")\n",
    "print(f\"OK dataframes ({len(ok_dataframes)}): {ok_dataframes}\")\n",
    "print(f\"Problematic dataframes ({len(problematic_dataframes)}): {problematic_dataframes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
